{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40301395-d23e-4e7c-9f7c-beb75d2a1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import matplotlib.pyplot as plt\n",
    "import moviepy.editor as mpy\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42004b1e-f1b1-49bd-a654-aecee5c5a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npy_to_gif(npy, filename):\n",
    "    clip = mpy.ImageSequenceClip(list(npy), fps=30)\n",
    "    clip.write_gif(filename)\n",
    "\n",
    "# Constant parameters used in Aruco methods\n",
    "ARUCO_PARAMETERS = aruco.DetectorParameters()\n",
    "ARUCO_REFINE=aruco.RefineParameters()\n",
    "ARUCO_DICT = aruco.getPredefinedDictionary(aruco.DICT_5X5_1000)\n",
    "detector = aruco.ArucoDetector(ARUCO_DICT, ARUCO_PARAMETERS)\n",
    "\n",
    "ARUCO_MARKER = aruco.generateImageMarker(ARUCO_DICT, 0, 256)\n",
    "plt.figure(figsize=(3,3)); plt.imshow(ARUCO_MARKER); plt.show()\n",
    "\n",
    "marker_length = 0.07 # [m] \n",
    "mtx = numpy.load(\"mtx.npy\")\n",
    "dist = numpy.load(\"dist.npy\")\n",
    "print(mtx); print(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a13b7-6ea0-4011-ada4-ab1b191e49ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_estimatePoseSingleMarkers(corners, marker_size, mtx, distortion):\n",
    "    '''\n",
    "    This will estimate the rvec and tvec for each of the marker corners detected by:\n",
    "       corners, ids, rejectedImgPoints = detector.detectMarkers(image)\n",
    "    corners - is an array of detected corners for each detected marker in the image\n",
    "    marker_size - is the size of the detected markers\n",
    "    mtx - is the camera matrix\n",
    "    distortion - is the camera distortion matrix\n",
    "    RETURN list of rvecs, tvecs, and trash (so that it corresponds to the old estimatePoseSingleMarkers())\n",
    "    '''\n",
    "    marker_points = numpy.array([[-marker_size / 2, marker_size / 2, 0],\n",
    "                              [marker_size / 2, marker_size / 2, 0],\n",
    "                              [marker_size / 2, -marker_size / 2, 0],\n",
    "                              [-marker_size / 2, -marker_size / 2, 0]], dtype=numpy.float32)\n",
    "    trash = []\n",
    "    rvecs = []\n",
    "    tvecs = []\n",
    "    \n",
    "    for c in corners:\n",
    "        nada, R, t = cv2.solvePnP(marker_points, c, mtx, distortion, False, cv2.SOLVEPNP_IPPE_SQUARE)\n",
    "        rvecs.append(R)\n",
    "        tvecs.append(t)\n",
    "        trash.append(nada)\n",
    "    return rvecs, tvecs, trash\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create vectors we'll be using for rotations and translations for postures\n",
    "#rvecs, tvecs = None, None\n",
    "\n",
    "#cam = cv2.VideoCapture('Input_Video.mp4')\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "XYZ = []\n",
    "RPY = []\n",
    "V_x = []\n",
    "V_y = []\n",
    "V_z = []\n",
    "\n",
    "while(cam.isOpened()):\n",
    "    # Capturing each frame of our video stream\n",
    "    ret, QueryImg = cam.read()\n",
    "    if ret == True:\n",
    "        # grayscale image\n",
    "        gray = cv2.cvtColor(QueryImg, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Detect Aruco markers\n",
    "        corners, ids, rejectedImgPoints = detector.detectMarkers(gray)\n",
    "        rvecs, tvecs, _ = my_estimatePoseSingleMarkers(corners, marker_length, mtx, dist)      \n",
    "        \n",
    "        # Make sure all 5 markers were detected before printing them out\n",
    "        #if ids is not None and len(ids) == 5:\n",
    "        if ids is not None:\n",
    "            # Print corners and ids to the console       \n",
    "            for i, corner in zip(ids, corners):\n",
    "                print('ID: {}; Corners: {}'.format(i, corner))\n",
    "\n",
    "            # Outline all of the markers detected in our image\n",
    "            QueryImg = aruco.drawDetectedMarkers(QueryImg, corners, borderColor=(0, 0, 255))\n",
    "            for idx in range(len(ids)):\n",
    "                QueryImg=cv2.drawFrameAxes(QueryImg,mtx,dist,rvecs[idx],tvecs[idx], marker_length/2)\n",
    "            \n",
    "                # R = cv2.Rodrigues(rvecs[idx])[0]\n",
    "                # R_T = R.T\n",
    "                # T = tvecs[idx]        \n",
    "                # xyz = numpy.dot(R_T, - T).squeeze()\n",
    "                # XYZ.append(xyz)\n",
    "                # rpy = numpy.deg2rad(cv2.RQDecomp3x3(R_T)[0])\n",
    "                # RPY.append(rpy)\n",
    "                # V_x.append(numpy.dot(R_T, numpy.array([1,0,0])))\n",
    "                # V_y.append(numpy.dot(R_T, numpy.array([0,1,0])))\n",
    "                # V_z.append(numpy.dot(R_T, numpy.array([0,0,1])))\n",
    "            R = cv2.Rodrigues(rvecs[0])[0] #it was rvecs in the original code\n",
    "            R_T = R.T\n",
    "            T = tvecs[0] #there was a transpose in the original code        \n",
    "            xyz = numpy.dot(R_T, - T).squeeze()\n",
    "            XYZ.append(xyz)\n",
    "            rpy = numpy.deg2rad(cv2.RQDecomp3x3(R_T)[0])\n",
    "            RPY.append(rpy)\n",
    "            V_x.append(numpy.dot(R_T, numpy.array([1,0,0])))\n",
    "            V_y.append(numpy.dot(R_T, numpy.array([0,1,0])))\n",
    "            V_z.append(numpy.dot(R_T, numpy.array([0,0,1])))\n",
    "        # Display our image\n",
    "        cv2.imshow('QueryImage', QueryImg)\n",
    "\n",
    "\n",
    "    # Exit at the end of the video on the 'q' keypress\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbb292-12cd-4e49-9c15-b545309aa959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_frames(elev=90, azim=270):\n",
    "    frames = []\n",
    "\n",
    "    for t in tqdm(range(len(XYZ))):\n",
    "        fig = plt.figure(figsize=(4,3))\n",
    "        ax = Axes3D(fig)\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "        ax.set_xlim(-2, 2); ax.set_ylim(-2, 2); ax.set_zlim(-2, 2)\n",
    "        ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\n",
    "\n",
    "        x, y, z = XYZ[t]\n",
    "        ux, vx, wx = V_x[t]\n",
    "        uy, vy, wy = V_y[t]\n",
    "        uz, vz, wz = V_z[t]\n",
    "\n",
    "        # draw marker\n",
    "        ax.scatter(0, 0, 0, color=\"k\")\n",
    "        ax.quiver(0, 0, 0, 1, 0, 0, length=1, color=\"r\")\n",
    "        ax.quiver(0, 0, 0, 0, 1, 0, length=1, color=\"g\")\n",
    "        ax.quiver(0, 0, 0, 0, 0, 1, length=1, color=\"b\")\n",
    "        ax.plot([-1,1,1,-1,-1], [-1,-1,1,1,-1], [0,0,0,0,0], color=\"k\", linestyle=\":\")\n",
    "\n",
    "        # draw camera\n",
    "        if t < 5:\n",
    "            ax.quiver(x, y, z, ux, vx, wx, length=0.5, color=\"k\")\n",
    "            ax.quiver(x, y, z, uy, vy, wy, length=0.5, color=\"k\")\n",
    "            ax.quiver(x, y, z, uz, vz, wz, length=0.5, color=\"k\")\n",
    "        else:\n",
    "            ax.quiver(x, y, z, ux, vx, wx, length=0.5, color=\"r\")\n",
    "            ax.quiver(x, y, z, uy, vy, wy, length=0.5, color=\"g\")\n",
    "            ax.quiver(x, y, z, uz, vz, wz, length=0.5, color=\"b\")\n",
    "\n",
    "        # save for animation\n",
    "        fig.canvas.draw()\n",
    "        frames.append(numpy.array(fig.canvas.renderer.buffer_rgba()))\n",
    "        plt.close()\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ced521-d676-4ad9-befb-18c7eef6e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = plot_all_frames(elev=105, azim=270)\n",
    "npy_to_gif(frames, \"sample1.gif\"); Image(url='sample1.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b308047-762b-4381-b3d1-2137ec37dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"xyz\"); plt.plot(XYZ); plt.show()  # 青:x, 橙:y, 緑:z\n",
    "plt.title(\"rpy\"); plt.plot(RPY); plt.show()  # 青:r, 橙:p, 緑:y\n",
    "plt.title(\"(v_x)\"); plt.plot(V_x); plt.show()\n",
    "plt.title(\"(v_y)\"); plt.plot(V_y); plt.show()\n",
    "plt.title(\"(v_z)\"); plt.plot(V_z); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078055ce-63d1-4102-91b0-265a73bc3588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f1762-a700-4cb9-922d-542c5abab9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aruco-camera-positioning)",
   "language": "python",
   "name": "aruco-camera-positioning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
